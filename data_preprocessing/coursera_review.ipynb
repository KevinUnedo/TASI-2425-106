{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Reviews Text Preprocessing Pipeline\n",
    "\n",
    "This notebook performs comprehensive text preprocessing on course reviews including:\n",
    "- Language detection (English only)\n",
    "- Lowercasing\n",
    "- Punctuation removal\n",
    "- Stopword removal\n",
    "- Non-English word filtering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\M.S.I\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\M.S.I\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\M.S.I\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from langdetect import detect, LangDetectException\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, words\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    \"\"\"Load and prepare the raw dataset\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Validate required columns\n",
    "    if 'reviews' not in df.columns:\n",
    "        raise ValueError(\"Column 'reviews' not found in dataset\")\n",
    "    \n",
    "    # Select only reviews column and drop NA\n",
    "    return df[['reviews']].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, english_vocab, stop_words, spanish_words):\n",
    "    \"\"\"Clean and process individual text\"\"\"\n",
    "    # Lowercase and remove punctuation/numbers\n",
    "    text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    \n",
    "    # Tokenize and filter\n",
    "    tokens = word_tokenize(text)\n",
    "    return ' '.join([\n",
    "        word for word in tokens \n",
    "        if (word not in stop_words and \n",
    "            word not in spanish_words and\n",
    "            word in english_vocab)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Main Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BEFORE PROCESSING ===\n",
      "Total reviews: 1454558\n",
      "Total words: 32575387\n",
      "Unique words: 283922\n",
      "\n",
      "=== AFTER PROCESSING ===\n",
      "Processed reviews: 1017953\n",
      "Total words: 11848738\n",
      "Unique words: 17136\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = load_data('../datasets/course_reviews.csv')\n",
    "\n",
    "# Before processing stats\n",
    "print(\"=== BEFORE PROCESSING ===\")\n",
    "print(f\"Total reviews: {len(df)}\")\n",
    "print(f\"Total words: {df['reviews'].apply(lambda x: len(x.split())).sum()}\")\n",
    "print(f\"Unique words: {len(Counter(' '.join(df['reviews']).split()))}\")\n",
    "\n",
    "# Initialize filters\n",
    "stop_words = set(stopwords.words('english'))\n",
    "spanish_words = {\"de\", \"curso\", \"que\", \"la\", \"el\", \"en\", \"para\", \"muy\"}\n",
    "english_vocab = set(words.words())\n",
    "\n",
    "# Process reviews\n",
    "processed_reviews = []\n",
    "for review in df['reviews']:\n",
    "    try:\n",
    "        if detect(review) == 'en':  # English only\n",
    "            cleaned = preprocess_text(review, english_vocab, stop_words, spanish_words)\n",
    "            if len(cleaned.split()) >= 3:  # Minimum 3 words\n",
    "                processed_reviews.append(cleaned)\n",
    "    except LangDetectException:\n",
    "        continue\n",
    "\n",
    "# Create output DataFrame\n",
    "df_processed = pd.DataFrame({'processed_reviews': processed_reviews})\n",
    "\n",
    "# After processing stats\n",
    "print(\"\\n=== AFTER PROCESSING ===\")\n",
    "print(f\"Processed reviews: {len(df_processed)}\")\n",
    "print(f\"Total words: {df_processed['processed_reviews'].apply(lambda x: len(x.split())).sum()}\")\n",
    "print(f\"Unique words: {len(Counter(' '.join(df_processed['processed_reviews']).split()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Saving Processed Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved ONLY processed reviews to: ../datasets/preprocessed_coursera_review.csv\n",
      "Sample processed reviews:\n",
      "                                   processed_reviews\n",
      "0  pretty dry able pass two complete happy usual ...\n",
      "1  would better experience video screen would sho...\n",
      "2  information perfect program little annoying wa...\n"
     ]
    }
   ],
   "source": [
    "output_path = '../datasets/preprocessed_coursera_review.csv'\n",
    "df_processed.to_csv(output_path, index=False)\n",
    "print(f\"\\nSaved ONLY processed reviews to: {output_path}\")\n",
    "print(\"Sample processed reviews:\")\n",
    "print(df_processed.head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
